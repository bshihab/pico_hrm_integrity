{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586d1daa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⬇️ Downloading data from Google Cloud Storage...\n",
      "✅ Download successful!\n",
      "Loading dataset...\n",
      "Training on 16000 samples...\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bilalshihab/dev/pico_hrm_integrity/.venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:106: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9586 - loss: 0.3268 - val_accuracy: 1.0000 - val_loss: 0.0435\n",
      "Epoch 2/20\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 759us/step - accuracy: 1.0000 - loss: 0.0198 - val_accuracy: 1.0000 - val_loss: 0.0086\n",
      "Epoch 3/20\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 771us/step - accuracy: 1.0000 - loss: 0.0055 - val_accuracy: 1.0000 - val_loss: 0.0034\n",
      "Epoch 4/20\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 927us/step - accuracy: 1.0000 - loss: 0.0025 - val_accuracy: 1.0000 - val_loss: 0.0018\n",
      "Epoch 5/20\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 1.0000 - val_loss: 0.0011\n",
      "Epoch 6/20\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 8.6004e-04 - val_accuracy: 1.0000 - val_loss: 6.8326e-04\n",
      "Epoch 7/20\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 963us/step - accuracy: 1.0000 - loss: 5.6833e-04 - val_accuracy: 1.0000 - val_loss: 4.6460e-04\n",
      "Epoch 8/20\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 778us/step - accuracy: 1.0000 - loss: 3.9289e-04 - val_accuracy: 1.0000 - val_loss: 3.2787e-04\n",
      "Epoch 9/20\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 746us/step - accuracy: 1.0000 - loss: 2.8040e-04 - val_accuracy: 1.0000 - val_loss: 2.3743e-04\n",
      "Epoch 10/20\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 2.0491e-04 - val_accuracy: 1.0000 - val_loss: 1.7561e-04\n",
      "Epoch 11/20\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 733us/step - accuracy: 1.0000 - loss: 1.5248e-04 - val_accuracy: 1.0000 - val_loss: 1.3189e-04\n",
      "Epoch 12/20\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 1.1508e-04 - val_accuracy: 1.0000 - val_loss: 1.0024e-04\n",
      "Epoch 13/20\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 931us/step - accuracy: 1.0000 - loss: 8.7796e-05 - val_accuracy: 1.0000 - val_loss: 7.6912e-05\n",
      "Epoch 14/20\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 770us/step - accuracy: 1.0000 - loss: 6.7579e-05 - val_accuracy: 1.0000 - val_loss: 5.9544e-05\n",
      "Epoch 15/20\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 681us/step - accuracy: 1.0000 - loss: 5.2367e-05 - val_accuracy: 1.0000 - val_loss: 4.6299e-05\n",
      "Epoch 16/20\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 680us/step - accuracy: 1.0000 - loss: 4.0799e-05 - val_accuracy: 1.0000 - val_loss: 3.6240e-05\n",
      "Epoch 17/20\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 717us/step - accuracy: 1.0000 - loss: 3.1946e-05 - val_accuracy: 1.0000 - val_loss: 2.8455e-05\n",
      "Epoch 18/20\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 713us/step - accuracy: 1.0000 - loss: 2.5113e-05 - val_accuracy: 1.0000 - val_loss: 2.2440e-05\n",
      "Epoch 19/20\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 697us/step - accuracy: 1.0000 - loss: 1.9799e-05 - val_accuracy: 1.0000 - val_loss: 1.7732e-05\n",
      "Epoch 20/20\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 681us/step - accuracy: 1.0000 - loss: 1.5654e-05 - val_accuracy: 1.0000 - val_loss: 1.4056e-05\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 494us/step - accuracy: 1.0000 - loss: 1.3927e-05\n",
      "Model Accuracy: 100.00%\n",
      "SUCCESS: Auto-updated header file at: /Users/bilalshihab/dev/pico_hrm_integrity/firmware/src/model_weights.h\n",
      "You can now Build the firmware immediately!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import os\n",
    "import requests\n",
    "import urllib.parse\n",
    "\n",
    "# config\n",
    "INPUT_SIZE = 10\n",
    "HIDDEN_SIZE = 8\n",
    "CLASSES = 3\n",
    "CSV_FILENAME = 'mitbih_test.csv'\n",
    "\n",
    "# google cloud config\n",
    "GCP_API_KEY = \"AIzaSyAYfA5H0TMQgfn0xsAamfsjI2qvS5dWwKg\"\n",
    "GCP_BUCKET_NAME = \"heart-data-repo-1\" \n",
    "GCP_OBJECT_NAME = \"mitbih_test.csv\"\n",
    "\n",
    "def get_google_cloud_url():\n",
    "    \"\"\"Constructs the authenticated Google Cloud Storage API URL.\"\"\"\n",
    "    encoded_name = urllib.parse.quote(GCP_OBJECT_NAME, safe='')\n",
    "    url = f\"https://storage.googleapis.com/storage/v1/b/{GCP_BUCKET_NAME}/o/{encoded_name}?alt=media&key={GCP_API_KEY}\"\n",
    "    return url\n",
    "\n",
    "def force_download_data(): \n",
    "    # to make sure that if the file is not available locally that we can download it on google cloud\n",
    "    if os.path.exists(CSV_FILENAME) and os.path.getsize(CSV_FILENAME) > 1000:\n",
    "        print(f\"Data present: {CSV_FILENAME}\")\n",
    "        return\n",
    "\n",
    "    target_url = get_google_cloud_url()\n",
    "    print(f\"Downloading data from Google Cloud Storage...\")\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(target_url)\n",
    "        if response.status_code == 200:\n",
    "            with open(CSV_FILENAME, 'wb') as f:\n",
    "                f.write(response.content)\n",
    "            print(\"Download successful!\")\n",
    "        else:\n",
    "            print(f\"Download failed (Status: {response.status_code})\")\n",
    "            print(f\"Response: {response.text}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Network error: {e}\")\n",
    "\n",
    "def load_data():\n",
    "    force_download_data()\n",
    "    \n",
    "    if not os.path.exists(CSV_FILENAME):\n",
    "        print(\"Error, File not found.\")\n",
    "        return None, None\n",
    "        \n",
    "    print(\"Loading dataset...\")\n",
    "    df = pd.read_csv(CSV_FILENAME, header=None)\n",
    "    \n",
    "    # only keep roles that deal with normal (0), s-type (1), and v-type (2) \n",
    "    df = df[df[187].isin([0.0, 1.0, 2.0])] \n",
    "    \n",
    "    # Train on FIRST 16,000 samples\n",
    "    X = df.iloc[:16000, 20:20+INPUT_SIZE].values\n",
    "    # Slice y to match X length\n",
    "    y = df.iloc[:16000, 187].values.astype(int)\n",
    "    \n",
    "    # one hot encoding, converting column numbers to vectors  \n",
    "    y = tf.keras.utils.to_categorical(y, num_classes=CLASSES) \n",
    "    return X, y\n",
    "\n",
    "def quantize_and_export_manual(model):\n",
    "    #  LAYER 1 (Hidden)\n",
    "    weights1, biases1 = model.layers[0].get_weights()\n",
    "    \n",
    "    w1_max = np.max(np.abs(weights1))\n",
    "    # maps largest weight to maximum 8-bit integer value\n",
    "    w1_scale = w1_max / 127.0 \n",
    "    \n",
    "    # scale up floats to 8 bit integers by dividing by scale and truncating\n",
    "    w1_int = (weights1 / w1_scale).astype(np.int8) \n",
    "    \n",
    "    #  LAYER 2 (Output) \n",
    "    weights2, biases2 = model.layers[1].get_weights() \n",
    "    \n",
    "    w2_max = np.max(np.abs(weights2))\n",
    "    # different scale than w1 because the max is different\n",
    "    w2_scale = w2_max / 127.0 \n",
    "    w2_int = (weights2 / w2_scale).astype(np.int8)\n",
    "    \n",
    "    #  GENERATE C HEADER CONTENT\n",
    "    c_code = \"// Auto-generated by train_tinyml.py\\n\"\n",
    "    c_code += \"#ifndef MODEL_WEIGHTS_H\\n#define MODEL_WEIGHTS_H\\n\\n\"\n",
    "    c_code += \"#include <stdint.h>\\n\\n\"\n",
    "\n",
    "    c_code += f\"// Layer 1 (Hidden) - Explicit Quantization\\n\"\n",
    "    c_code += f\"const float W1_SCALE = {w1_scale:.12f};\\n\"\n",
    "    c_code += f\"const int8_t W1[{INPUT_SIZE}][{HIDDEN_SIZE}] = {{\\n\"\n",
    "    for i in range(INPUT_SIZE):\n",
    "        row = \", \".join([f\"{w:4d}\" for w in w1_int[i]])\n",
    "        c_code += f\"    {{{row}}},\\n\"\n",
    "    c_code += \"};\\n\"\n",
    "    c_code += f\"const float B1[{HIDDEN_SIZE}] = {{ \" + \", \".join([f\"{b:.6f}\" for b in biases1]) + \" };\\n\\n\"\n",
    "\n",
    "    c_code += f\"// Layer 2 (Output) - Explicit Quantization\\n\"\n",
    "    c_code += f\"const float W2_SCALE = {w2_scale:.12f};\\n\"\n",
    "    # must print 8-bit int for pico to run more efficiently, but pico will scale it back up before running inference.\n",
    "    c_code += f\"const int8_t W2[{HIDDEN_SIZE}][{CLASSES}] = {{\\n\"\n",
    "    for i in range(HIDDEN_SIZE):\n",
    "        row = \", \".join([f\"{w:4d}\" for w in w2_int[i]])\n",
    "        c_code += f\"    {{{row}}},\\n\"\n",
    "    c_code += \"};\\n\"\n",
    "    c_code += f\"const float B2[{CLASSES}] = {{ \" + \", \".join([f\"{b:.6f}\" for b in biases2]) + \" };\\n\"\n",
    "    \n",
    "    c_code += \"\\n#endif // MODEL_WEIGHTS_H\\n\"\n",
    "\n",
    "    #  SAVE TO FILE (ROBUST PATH FINDING) \n",
    "    possible_paths = [\n",
    "        \"../firmware/src/model_weights.h\",        # If running from training/ folder\n",
    "        \"firmware/src/model_weights.h\",           # If running from root folder\n",
    "        \"src/model_weights.h\",                    # If running from inside firmware/\n",
    "        \"/content/model_weights.h\"                # Google Colab Default\n",
    "    ]\n",
    "\n",
    "    saved = False\n",
    "    for path in possible_paths:\n",
    "        dir_name = os.path.dirname(path)\n",
    "        if os.path.exists(dir_name) or dir_name == \"/content\":\n",
    "            try:\n",
    "                with open(path, \"w\") as f:\n",
    "                    f.write(c_code)\n",
    "                print(f\"SUCCESS: Auto-updated header file at: {os.path.abspath(path)}\")\n",
    "                print(\"You can now Build the firmware immediately!\")\n",
    "                saved = True\n",
    "                break\n",
    "            except Exception as e:\n",
    "                pass \n",
    "\n",
    "    if not saved:\n",
    "        filename = \"model_weights.h\"\n",
    "        with open(filename, \"w\") as f:\n",
    "            f.write(c_code)\n",
    "        print(f\"WARNING: Could not find firmware folder automatically.\")\n",
    "        print(f\"Saved '{filename}' to current directory.\")\n",
    "        print(\"ACTION: Please move this file into 'firmware/src/' manually.\")\n",
    "\n",
    "def main():\n",
    "    X, y = load_data() \n",
    "    if X is None: return\n",
    "\n",
    "    print(f\"Training on {len(X)} samples...\")\n",
    "    \n",
    "    model = Sequential([\n",
    "        Dense(HIDDEN_SIZE, input_dim=INPUT_SIZE, activation='relu'),\n",
    "        # converting scores to probabilities\n",
    "        Dense(CLASSES, activation='softmax') \n",
    "    ])\n",
    "    \n",
    "    # we use adam optimizer becayse idk?\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    # Train\n",
    "    model.fit(X, y, epochs=20, batch_size=32, validation_split=0.2, verbose=1)\n",
    "    \n",
    "    loss, acc = model.evaluate(X, y, verbose=1)\n",
    "    print(f\"Model Accuracy: {acc*100:.2f}%\")\n",
    "    \n",
    "    # Run the automated export\n",
    "    quantize_and_export_manual(model)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
